mr:
  type: family
  metadata:
    name: Vicuna
    version: 1.0.0
    refs:
    - https://lmsys.org/blog/2023-03-30-vicuna/index.html
    publisher: LMSYS ORG
    model_type: Language Model
    release_date: '2023-03-30'
  tags:
  - opensource
  question_sets:
  - fmti2023
  model:
    blackbox_external_model_access: 1
    capabilities_demonstration: 1
    capabilities_description: 0
    centralized_model_documentation: 1
    evaluation_of_capabilities: 1
    external_model_access_protocol: 1
    external_reproducibility_of_capabilities_evaluation: 1
    external_reproducibility_of_intentional_harm_evaluation: 0
    external_reproducibility_of_mitigations_evaluation: 0
    external_reproducibility_of_trustworthiness_evaluation: 0
    external_reproducibility_of_unintentional_harm_evaluation: 1
    full_external_model_access: 1
    inference_compute_evaluation: 0
    inference_duration_evaluation: 1
    input_modality: 1
    intentional_harm_evaluation: 0
    limitations_demonstration: 0
    limitations_description: 1
    mitigations_demonstration: 1
    mitigations_description: 1
    mitigations_evaluation: 1
    model_architecture: 1
    asset_license: 1
    model_components: 1
    model_size: 1
    output_modality: 1
    risks_demonstration: 1
    risks_description: 1
    third_party_capabilities_evaluation: 0
    third_party_evaluation_of_limitations: 1
    third_party_mitigations_evaluation: 0
    third_party_risks_evaluation: 0
    trustworthiness_evaluation: 0
    unintentional_harm_evaluation: 1
  upstream:
    additional_dependencies: 1
    broader_environmental_impact: 0
    carbon_emissions: 1
    compute_hardware: 0
    compute_usage: 0
    core_frameworks: 0
    data_augmentation: 1
    copyrighted_data: 0
    data_creators: 0
    data_curation: 1
    data_license_status: 0
    data_size: 1
    data_source_selection: 0
    data_sources: 0
    development_duration: 1
    direct_external_data_access: 0
    employment_of_data_laborers: 0
    energy_usage: 1
    geographic_distribution_of_data_laborers: 0
    hardware_owner: 1
    harmful_data_filtration: 1
    instructions_for_creating_data: 1
    labor_protections: 0
    mitigations_for_copyright: 0
    mitigations_for_privacy: 1
    model_objectives: 1
    model_stages: 1
    personal_information_in_data: 0
    queryable_external_data_access: 0
    third_party_partners: 0
    use_of_human_labor: 1
    wages: 0
    intended_use:
    - Research and academic purposes
    - Open-source innovation
    - Enhancement of chatbot technology
    - Public demonstration and education
    - Non-commercial use
    factors:
    - Model's ability to understand and generate human-like responses
    - Performance comparison with other LLM-based models like ChatGPT and Alpaca
    - The model's handling of multi-turn conversations
    - Capability to be fine-tuned on specific use-cases or datasets
    - Cost-effectiveness of training and deploying the model
    evaluation_data:
    - Use of GPT-4 for preliminary evaluation and chatbot performance assessment
    - Collection of 70K user-shared ChatGPT conversations from ShareGPT.com
    - Creation of 80 diverse questions for model quality evaluation
    - Comparison between Vicuna, LLaMA, Alpaca, ChatGPT, and Bard
    - Assessment based on categories like Fermi problems, roleplay scenarios, and
      coding/math tasks
    training_data:
    - Approximately 70K user-shared conversations from ShareGPT.com
    - Data converted from HTML to markdown and filtered for quality
    - Long conversations segmented into smaller parts to fit model's context length
    - Enhanced training scripts from Stanford Alpaca project
    - Publicly available datasets totaling 1T tokens for initial LLaMA model
    additional_information:
    - The model is built by fine-tuning LLaMA with conversational data
    - Designed to generate more detailed and structured responses
    - Training cost was significantly reduced by using managed spot instances
    - A lightweight distributed serving system implemented for model deployment
    - Not all chatbots' limitations, such as reasoning or mathematics, can be addressed
    recommendations:
    - Best suited for research, academic, and open-source development purposes
    - Use in conjunction with moderation APIs to address potential safety concerns
    - Further fine-tuning with specific datasets for targeted applications encouraged
    - Continuous evaluation and comparison with emerging models for improvements
    - Not intended for direct commercial use without proper evaluation
    ethical_considerations:
    - Potential for biased responses based on training data
    - Need for continuous monitoring to mitigate toxicity or misinformation
    - Possibility of misuse in generating deceptive or harmful content
    - Importance of transparent usage and limitations disclosure to users
    - Commitment to non-commercial use to respect data and model licensing agreements
  downstream:
    affected_individuals: 0
    affected_market_sectors: 0
    centralized_documentation_for_downstream_use: 1
    change_log: 1
    deprecation_policy: 1
    distribution_channels: 1
    documentation_for_responsible_downstream_use: 1
    downstream_applications: 1
    feedback_mechanism: 1
    feedback_summary: 0
    geographic_statistics: 0
    government_inquiries: 0
    interoperability_of_usage_and_model_behavior_policies: 0
    justification_for_enforcement_action: 0
    detection_of_machine_generated_content: 0
    model_behavior_policy_enforcement: 0
    monitoring_mechanism: 0
    permitted_restricted_and_prohibited_model_behaviors: 0
    permitted_restricted_and_prohibited_uses: 1
    permitted_and_prohibited_use_of_user_data: 1
    permitted_and_prohibited_users: 1
    products_and_services: 1
    redress_mechanism: 0
    release_decision_making_protocol: 0
    release_process: 1
    terms_of_service: 1
    usage_data_access_protocol: 0
    usage_disclaimers: 1
    usage_policy_enforcement: 0
    usage_policy_violation_appeals_mechanism: 0
    usage_reports: 0
    user_data_protection_policy: 1
    user_interaction_with_ai_system: 1
    versioning_protocol: 1
