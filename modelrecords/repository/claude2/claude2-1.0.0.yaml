mr:
  metadata:
    name: Claude 2
    refs:
    - https://www-cdn.anthropic.com/bd2a28d2535bfb0494cc8e2a3bf135d2e7523226/Model-Card-Claude-2.pdf
    version: '2'
    publisher: Anthropic
    model_type: Large Language Model
    release_date: '2023-07-01'
  question_sets:
  - fmti2023
  model:
    blackbox_external_model_access: 1
    capabilities_demonstration: 1
    capabilities_description: 1
    centralized_model_documentation: 1
    evaluation_of_capabilities: 1
    external_model_access_protocol: 0
    external_reproducibility_of_capabilities_evaluation: 1
    external_reproducibility_of_intentional_harm_evaluation: 0
    external_reproducibility_of_mitigations_evaluation: 0
    external_reproducibility_of_trustworthiness_evaluation: 0
    external_reproducibility_of_unintentional_harm_evaluation: 0
    full_external_model_access: 0
    inference_compute_evaluation: 0
    inference_duration_evaluation: 0
    input_modality: 1
    intentional_harm_evaluation: 0
    limitations_demonstration: 0
    limitations_description: 1
    mitigations_demonstration: 0
    mitigations_description: 1
    mitigations_evaluation: 1
    model_architecture: 1
    asset_license: 0
    model_components: 0
    model_size: 0
    output_modality: 1
    risks_demonstration: 0
    risks_description: 1
    third_party_capabilities_evaluation: 0
    third_party_evaluation_of_limitations: 1
    third_party_mitigations_evaluation: 0
    third_party_risks_evaluation: 1
    trustworthiness_evaluation: 0
    unintentional_harm_evaluation: 0
  downstream:
    affected_individuals: 0
    affected_market_sectors: 0
    centralized_documentation_for_downstream_use: 1
    change_log: 0
    deprecation_policy: 0
    distribution_channels: 1
    documentation_for_responsible_downstream_use: 1
    downstream_applications: 0
    feedback_mechanism: 1
    feedback_summary: 0
    geographic_statistics: 0
    government_inquiries: 0
    interoperability_of_usage_and_model_behavior_policies: 1
    justification_for_enforcement_action: 0
    detection_of_machine_generated_content: 0
    model_behavior_policy_enforcement: 0
    monitoring_mechanism: 0
    permitted_restricted_and_prohibited_model_behaviors: 1
    permitted_restricted_and_prohibited_uses: 1
    permitted_and_prohibited_use_of_user_data: 1
    permitted_and_prohibited_users: 1
    products_and_services: 1
    redress_mechanism: 0
    release_decision_making_protocol: 0
    release_process: 1
    terms_of_service: 1
    usage_data_access_protocol: 0
    usage_disclaimers: 1
    usage_policy_enforcement: 1
    usage_policy_violation_appeals_mechanism: 0
    usage_reports: 0
    user_data_protection_policy: 1
    user_interaction_with_ai_system: 0
    versioning_protocol: 1
  upstream:
    additional_dependencies: 1
    broader_environmental_impact: 0
    carbon_emissions: 0
    compute_hardware: 0
    compute_usage: 0
    core_frameworks: 0
    data_augmentation: 0
    copyrighted_data: 0
    data_creators: 0
    data_curation: 0
    data_license_status: 0
    data_size: 0
    data_source_selection: 0
    data_sources: 0
    development_duration: 0
    direct_external_data_access: 0
    employment_of_data_laborers: 0
    energy_usage: 0
    geographic_distribution_of_data_laborers: 0
    hardware_owner: 0
    harmful_data_filtration: 0
    instructions_for_creating_data: 1
    labor_protections: 0
    mitigations_for_copyright: 0
    mitigations_for_privacy: 0
    model_objectives: 1
    model_stages: 1
    personal_information_in_data: 0
    queryable_external_data_access: 0
    third_party_partners: 0
    use_of_human_labor: 0
    wages: 1
    intended_use:
    - general, open-ended conversation
    - search, writing, editing, outlining, and summarizing text
    - coding
    - providing helpful advice about a broad range of subjects
    - support creative or literary use cases
    factors:
    - Claude models may confabulate, getting facts wrong or fabricating details
    - Not to be used in high stakes situations on their own
    - Do not currently search the web, operating with data from before early 2023
    - Cannot be assumed to have updated information or web search capabilities unless
      specifically indicated
    - Multilingual capabilities vary, lower performance on low-resource languages
    evaluation_data:
    - Suite of evaluations including capabilities, safety, and alignment evaluations
    - Human preference data to calculate per-task Elo scores
    - BBQ bias evaluations using a multiple choice Q and A format designed for a U.S.
      English-speaking context
    - TruthfulQA evaluation for determining accurate and truthful responses in adversarial
      settings
    - Held-out set of prompts including harmful requests and 'jailbreaks' for harmlessness
      evaluation
    training_data:
    - Proprietary mix of publicly available internet data, licensed datasets, and
      data shared by users or crowd workers
    - Some human feedback data used for fine-tuning made public
    - Training data cutoff in early 2023
    - Around 10 percent of the data included was non-English
    - Includes data on recent events up to early 2023, but may generate confabulations
    additional_information:
    - Continuous evolution from early helpful and harmless language assistants
    - Use of a Constitution - a set of ethical and behavioral principles
    - Engagement in red teaming and safety audits with external organizations
    - Focus on improving helpfulness, honesty, and harmlessness
    - Ongoing efforts to mitigate bias and ensure ethical use
    recommendations:
    - Should be supplemented by human review in high-stakes use cases
    - Not recommended for uses requiring up-to-date web searching
    - Use caution in applications involving low-resource languages
    - Follow the Acceptable Use Policy to avoid misuse
    - Stay informed about updates and improvements for best application practices
    ethical_considerations:
    - Trained to avoid sexist, racist, and toxic outputs
    - Designed to prevent aiding in illegal or unethical activities
    - Models can still make mistakes and may be jailbroken
    - Training involves principles to guide model outputs ethically
    - Continuous work to minimize bias and harmful outputs
  type: model
