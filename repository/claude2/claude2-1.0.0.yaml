pc:
  metadata:
    name: Claude 2
    refs:
    - https://www-cdn.anthropic.com/bd2a28d2535bfb0494cc8e2a3bf135d2e7523226/Model-Card-Claude-2.pdf
    version: '2'
    publisher: Anthropic
    model_type: Large Language Model
    release_date: '2023-07-01'
  question_sets:
  - fmti2023
  model:
    blackbox_external_model_access: 1
    capabilities_demonstration: 1
    capabilities_description: 1
    centralized_model_documentation: 1
    evaluation_of_capabilities: 1
    external_model_access_protocol: 0
    external_reproducibility_of_capabilities_evaluation: 1
    external_reproducibility_of_intentional_harm_evaluation: 0
    external_reproducibility_of_mitigations_evaluation: 0
    external_reproducibility_of_trustworthiness_evaluation: 0
    external_reproducibility_of_unintentional_harm_evaluation: 0
    full_external_model_access: 0
    inference_compute_evaluation: 0
    inference_duration_evaluation: 0
    input_modality: 1
    intentional_harm_evaluation: 0
    limitations_demonstration: 0
    limitations_description: 1
    mitigations_demonstration: 0
    mitigations_description: 1
    mitigations_evaluation: 1
    model_architecture: 1
    asset_license: 0
    model_components: 0
    model_size: 0
    output_modality: 1
    risks_demonstration: 0
    risks_description: 1
    third_party_capabilities_evaluation: 0
    third_party_evaluation_of_limitations: 1
    third_party_mitigations_evaluation: 0
    third_party_risks_evaluation: 1
    trustworthiness_evaluation: 0
    unintentional_harm_evaluation: 0
  downstream:
    affected_individuals: 0
    affected_market_sectors: 0
    centralized_documentation_for_downstream_use: 1
    change_log: 0
    deprecation_policy: 0
    distribution_channels: 1
    documentation_for_responsible_downstream_use: 1
    downstream_applications: 0
    feedback_mechanism: 1
    feedback_summary: 0
    geographic_statistics: 0
    government_inquiries: 0
    interoperability_of_usage_and_model_behavior_policies: 1
    justification_for_enforcement_action: 0
    detection_of_machine_generated_content: 0
    model_behavior_policy_enforcement: 0
    monitoring_mechanism: 0
    permitted_restricted_and_prohibited_model_behaviors: 1
    permitted_restricted_and_prohibited_uses: 1
    permitted_and_prohibited_use_of_user_data: 1
    permitted_and_prohibited_users: 1
    products_and_services: 1
    redress_mechanism: 0
    release_decision_making_protocol: 0
    release_process: 1
    terms_of_service: 1
    usage_data_access_protocol: 0
    usage_disclaimers: 1
    usage_policy_enforcement: 1
    usage_policy_violation_appeals_mechanism: 0
    usage_reports: 0
    user_data_protection_policy: 1
    user_interaction_with_ai_system: 0
    versioning_protocol: 1
  upstream:
    additional_dependencies: 1
    broader_environmental_impact: 0
    carbon_emissions: 0
    compute_hardware: 0
    compute_usage: 0
    core_frameworks: 0
    data_augmentation: 0
    copyrighted_data: 0
    data_creators: 0
    data_curation: 0
    data_license_status: 0
    data_size: 0
    data_source_selection: 0
    data_sources: 0
    development_duration: 0
    direct_external_data_access: 0
    employment_of_data_laborers: 0
    energy_usage: 0
    geographic_distribution_of_data_laborers: 0
    hardware_owner: 0
    harmful_data_filtration: 0
    instructions_for_creating_data: 1
    labor_protections: 0
    mitigations_for_copyright: 0
    mitigations_for_privacy: 0
    model_objectives: 1
    model_stages: 1
    personal_information_in_data: 0
    queryable_external_data_access: 0
    third_party_partners: 0
    use_of_human_labor: 0
    wages: 1
    intended_use:
    - General, open-ended conversation
    - Search, writing, editing, outlining, and summarizing text
    - Coding
    - Providing helpful advice about a broad range of subjects
    - Support creative or literary use cases
    factors:
    - Confabulating – getting facts wrong, hallucinating details, and filling in gaps
      in knowledge with fabrication
    - Not searching the web or using data after early 2023
    - Performance on low-resource languages is weaker
    - Should not be used in high stakes situations without human review
    - Not designed to replace professionals (like lawyers) in decision-making processes
    evaluation_data:
    - 'Description: Human preference data used to calculate per-task Elo scores across
      different versions of Claude'
    - 'Description: Data from red-teaming task, asking crowdworkers to roleplay adversarial
      scenarios'
    - 'Description: Bias Benchmark for QA (BBQ) evaluations measuring stereotype biases'
    - 'Description: TruthfulQA evaluation to determine if models output accurate and
      truthful responses'
    - 'Description: Held out prompts from red-teaming work and AI model ‘jailbreaks’'
    training_data:
    - 'Description: Proprietary mix of publicly available information from the Internet'
    - 'Description: Datasets licensed from third-party businesses'
    - 'Description: Data affirmatively shared by users or provided by crowd workers'
    - 'Description: Roughly 10 percent of the data included was non-English'
    - 'Description: Training data cutoff in early 2023'
    additional_information:
    - Continuous evolution from earlier models
    - Use of RLHF and Constitutional AI for training
    - Does not represent a transformative change but continuous improvement
    - Developed by Anthropic and released in July 2023
    - Model data cuts off in early 2023
    recommendations:
    - Use in conjunction with human review, especially in high stakes scenarios
    - Consider augmenting with web search for more current information
    - Ensure appropriateness for the intended audience, especially in multilingual
      contexts
    - Avoid relying on the model for legal, medical, or other professional advice
    - Leverage the model's steering capabilities for creative and literary uses
    ethical_considerations:
    - Training models to avoid sexist, racist, and toxic outputs
    - Avoid helping humans engage in illegal or unethical activities
    - Models can still make mistakes and be jailbroken
    - Ethical considerations shape Acceptable Use Policy and Trust and Safety processes
    - Continuous effort to improve helpfulness, honesty, and harmlessness of the models
